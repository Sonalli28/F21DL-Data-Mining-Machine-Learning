{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b85246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is \n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daade5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_train = pd.read_csv('x_train_all.csv')\n",
    "y_train = pd.read_csv('y_train_all.csv')\n",
    "x_test = pd.read_csv('x_test_all.csv')\n",
    "y_test = pd.read_csv('y_test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f5073e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specs</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>1263</td>\n",
       "      <td>150633.369191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1264</td>\n",
       "      <td>148051.674998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>1216</td>\n",
       "      <td>144958.677289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1311</td>\n",
       "      <td>144287.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>1215</td>\n",
       "      <td>140869.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>1168</td>\n",
       "      <td>136870.402181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1312</td>\n",
       "      <td>134552.189285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1310</td>\n",
       "      <td>131485.851171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>1121</td>\n",
       "      <td>129990.460474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>1262</td>\n",
       "      <td>129791.235186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>1120</td>\n",
       "      <td>126659.846451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>1167</td>\n",
       "      <td>125733.529410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1265</td>\n",
       "      <td>124195.693018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>1169</td>\n",
       "      <td>122427.150013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>1217</td>\n",
       "      <td>121176.221003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1073</td>\n",
       "      <td>119383.675559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1214</td>\n",
       "      <td>119281.998441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>1358</td>\n",
       "      <td>117699.176838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1313</td>\n",
       "      <td>117513.053251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>1359</td>\n",
       "      <td>115299.392732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>1074</td>\n",
       "      <td>112818.456328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>746</td>\n",
       "      <td>112200.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>747</td>\n",
       "      <td>111012.409836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1119</td>\n",
       "      <td>110514.431437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1314</td>\n",
       "      <td>108759.501898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>698</td>\n",
       "      <td>108150.572550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>1695</td>\n",
       "      <td>107843.126094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>1122</td>\n",
       "      <td>107766.961595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1166</td>\n",
       "      <td>107759.001390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>1086</td>\n",
       "      <td>107116.762591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>697</td>\n",
       "      <td>106720.383982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1072</td>\n",
       "      <td>106720.378407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>1696</td>\n",
       "      <td>106304.435457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741</td>\n",
       "      <td>105667.428026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>648</td>\n",
       "      <td>104709.723011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>1038</td>\n",
       "      <td>104619.978234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740</td>\n",
       "      <td>104619.045436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>693</td>\n",
       "      <td>104461.744442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1309</td>\n",
       "      <td>104397.930508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>647</td>\n",
       "      <td>104192.232801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1266</td>\n",
       "      <td>103866.479599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1315</td>\n",
       "      <td>103712.267863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>694</td>\n",
       "      <td>103483.914170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1135</td>\n",
       "      <td>103404.438362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>745</td>\n",
       "      <td>103354.641544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>1026</td>\n",
       "      <td>103229.448544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>1360</td>\n",
       "      <td>103081.072834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>794</td>\n",
       "      <td>102852.562668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>102702.543059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>696</td>\n",
       "      <td>102664.170227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Specs          Score\n",
       "1263  1263  150633.369191\n",
       "1264  1264  148051.674998\n",
       "1216  1216  144958.677289\n",
       "1311  1311  144287.318409\n",
       "1215  1215  140869.000438\n",
       "1168  1168  136870.402181\n",
       "1312  1312  134552.189285\n",
       "1310  1310  131485.851171\n",
       "1121  1121  129990.460474\n",
       "1262  1262  129791.235186\n",
       "1120  1120  126659.846451\n",
       "1167  1167  125733.529410\n",
       "1265  1265  124195.693018\n",
       "1169  1169  122427.150013\n",
       "1217  1217  121176.221003\n",
       "1073  1073  119383.675559\n",
       "1214  1214  119281.998441\n",
       "1358  1358  117699.176838\n",
       "1313  1313  117513.053251\n",
       "1359  1359  115299.392732\n",
       "1074  1074  112818.456328\n",
       "746    746  112200.384615\n",
       "747    747  111012.409836\n",
       "1119  1119  110514.431437\n",
       "1314  1314  108759.501898\n",
       "698    698  108150.572550\n",
       "1695  1695  107843.126094\n",
       "1122  1122  107766.961595\n",
       "1166  1166  107759.001390\n",
       "1086  1086  107116.762591\n",
       "697    697  106720.383982\n",
       "1072  1072  106720.378407\n",
       "1696  1696  106304.435457\n",
       "741    741  105667.428026\n",
       "648    648  104709.723011\n",
       "1038  1038  104619.978234\n",
       "740    740  104619.045436\n",
       "693    693  104461.744442\n",
       "1309  1309  104397.930508\n",
       "647    647  104192.232801\n",
       "1266  1266  103866.479599\n",
       "1315  1315  103712.267863\n",
       "694    694  103483.914170\n",
       "1135  1135  103404.438362\n",
       "745    745  103354.641544\n",
       "1026  1026  103229.448544\n",
       "1360  1360  103081.072834\n",
       "794    794  102852.562668\n",
       "795    795  102702.543059\n",
       "696    696  102664.170227"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "data = pd.read_csv('x_train_all.csv')\n",
    "datatype = pd.read_csv('y_train_all.csv')\n",
    "X1 = data.iloc[:,0:2304]  #independent columns\n",
    "y1 = datatype.iloc[:,-1]    #target column i.e price range\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=2)\n",
    "fit = bestfeatures.fit(X1,y1)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X1.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "#print(featureScores.nlargest(10,'Score'))  #print 10 best features\n",
    "featureScoresAll50 = featureScores.nlargest(50,'Score')\n",
    "featureScoresAll50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a71250f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=42)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "#30% dataset\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42) #Max_depth values also changes the accuracy scores\n",
    "x_train_30, x_test, y_train_30, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "tree_clf.fit(x_train_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b5e57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_30=tree_clf.predict(x_train_30)\n",
    "y_pred_test_30=tree_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0277ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.9929234851835471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_accuracy_30 = accuracy_score(y_train_30, y_pred_train_30)\n",
    "print(\"Accuracy on the training set:\", train_accuracy_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "40329320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the testing set: 0.8211214310285517\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_30 = accuracy_score(y_test, y_pred_test_30)\n",
    "print(\"Accuracy on the testing set:\", test_accuracy_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ce08756c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=42)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#60% dataset\n",
    "x_train_60, x_test, y_train_60, y_test = train_test_split(x_train, y_train, test_size=0.6, random_state=42)\n",
    "tree_clf.fit(x_train_60, y_train_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fa17e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_60=tree_clf.predict(x_train_60)\n",
    "y_pred_test_60=tree_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "70c98584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.478844169246646\n"
     ]
    }
   ],
   "source": [
    "train_accuracy_60 = accuracy_score(y_train_60, y_pred_train_60)\n",
    "print(\"Accuracy on the training set:\", train_accuracy_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "83cf9a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the testing set: 0.45614035087719296\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_60 = accuracy_score(y_test, y_pred_test_60)\n",
    "print(\"Accuracy on the testing set:\", test_accuracy_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2172f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4449358690844759\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_clf.fit(x_train_30,y_train_30)\n",
    "print(train_accuracy_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "518c5428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated accuracy scores: [0.44509948 0.42520265 0.43773029 0.45648968 0.4159292 ]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation:\n",
    "#30%\n",
    "from sklearn.model_selection import cross_val_score\n",
    "tree_clf=DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "cross_score_30 = cross_val_score(tree_clf, x_train_30, y_train_30, cv=5)  # Adjust the number of folds as needed\n",
    "print(\"Cross-validated accuracy scores:\", cross_score_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b1f79b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated accuracy scores: [0.4742268  0.46193548 0.47096774 0.47612903 0.44903226]\n"
     ]
    }
   ],
   "source": [
    "#60%\n",
    "cross_score_60 = cross_val_score(tree_clf, x_train_60, y_train_60, cv=5)  \n",
    "print(\"Cross-validated accuracy scores:\", cross_score_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80345284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for Training:  0.508438639711504\n",
      "Precision Score for Testing:  0.48930856306366155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ashwin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Ashwin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Precision Score:\n",
    "#30%\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score_train_30 = precision_score(y_train_30, y_pred_train_30,average=\"weighted\")\n",
    "print(\"Precision Score for Training: \",precision_score_train_30)\n",
    "precision_score_test_30 = precision_score(y_test, y_pred_test_30,average=\"weighted\")\n",
    "print(\"Precision Score for Testing: \",precision_score_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a97e320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for Training:  0.5015591144995052\n",
      "Precision Score for Testing:  0.48737984849671323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ashwin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Ashwin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#60%\n",
    "precision_score_train_60 = precision_score(y_train_60, y_pred_train_60,average=\"weighted\")\n",
    "print(\"Precision Score for Training: \",precision_score_train_60)\n",
    "precision_score_test_60 = precision_score(y_test, y_pred_test_60,average=\"weighted\")\n",
    "print(\"Precision Score for Testing: \",precision_score_test_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f00b66d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score for Training:  0.4449358690844759\n",
      "Recall Score for Testing:  0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "#Recall Score:\n",
    "#30%\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score_train_30 = recall_score(y_train_30, y_pred_train_30,average=\"weighted\")\n",
    "print(\"Recall Score for Training: \", recall_score_train_30)\n",
    "recall_score_test_30 = recall_score(y_test, y_pred_test_30,average=\"weighted\")\n",
    "print(\"Recall Score for Testing: \", recall_score_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5aed70b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score for Training:  0.478844169246646\n",
      "Recall Score for Training:  0.45614035087719296\n"
     ]
    }
   ],
   "source": [
    "#60%\n",
    "recall_score_train_60 = recall_score(y_train_60, y_pred_train_60,average=\"weighted\")\n",
    "print(\"Recall Score for Training: \", recall_score_train_60)\n",
    "recall_score_test_60 = recall_score(y_test, y_pred_test_60,average=\"weighted\")\n",
    "print(\"Recall Score for Testing: \",recall_score_test_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e02f591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training:  0.40194808174946645\n",
      "F1 Score for Testing:  0.3991434872415531\n"
     ]
    }
   ],
   "source": [
    "#F1 Score:\n",
    "#30%\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score_train_30 = f1_score(y_train_30, y_pred_train_30, average='weighted')\n",
    "print(\"F1 Score for Training: \",f1_score_train_30)\n",
    "f1_score_test_30 = f1_score(y_test, y_pred_test_30, average='weighted')\n",
    "print(\"F1 Score for Testing: \",f1_score_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "486189f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Training:  0.45080868746710656\n",
      "F1 Score for Testing:  0.43076101364505004\n"
     ]
    }
   ],
   "source": [
    "#60%\n",
    "f1_score_train_60 = f1_score(y_train_60, y_pred_train_60, average='weighted')\n",
    "print(\"F1 Score for Training: \",f1_score_train_60)\n",
    "f1_score_test_60 = f1_score(y_test, y_pred_test_60, average='weighted')\n",
    "print(\"F1 Score for Testing: \",f1_score_test_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2c2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0f81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d703705a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
